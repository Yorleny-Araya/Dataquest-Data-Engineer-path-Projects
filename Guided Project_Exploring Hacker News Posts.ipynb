{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this project, we will explore a dataset of submissions to the thecnology site [Hacker News](https://news.ycombinator.com/). We are going to focus our analysis on those posts that begin with `Ask HN` or `Show HN` in order to compare them and determine:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "For this purpose, we are going to use [a dataset](https://www.kaggle.com/hacker-news/hacker-news-posts) extracted from the Hacker News site. This dataset has been reduced from almost 300,000 entries to around 20,000 by removing those submissions without any comments and then selecting a random sample from the remaining entries.\n",
    "\n",
    "The dataset has the following columns:\n",
    "\n",
    "- `id`: The unique identifier from Hacker News for the post.\n",
    "- `title`: The title of the post.\n",
    "- `url`: The URL that the posts links to, if it the post has an URL.\n",
    "- `num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- `num_comments`: The number of comments that were made on the post.\n",
    "- `author`: The username of the person who submitted the post.\n",
    "- `created_at`: The date and time at which the post was submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start by opening and reading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# Opening the file and storing it in a variable.\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first rows of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "# Printing the first five rows of the dataset.\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Headers From a List of Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that the fist row of the dataset contains the header row. In order to properly analyze the data, we are going to remove the header from the rest of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the header in a separate variable and then removing it from the dataset.\n",
    "headers = hn[0]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the header and the first five rows of the remaining dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "# Printing the headers variable and the first five rows of the dataset.\n",
    "print(headers, '\\n')\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to separate the posts that start with `Ask HN` or `Show HN` from the rest, given that we want to make our analysis with those specific posts.\n",
    "\n",
    "For this purpose, we are going to separate those posts into two diferent lists, and store the rest of the dataset in a third list. We start by creating three empty lists to store each kind of post in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty lists to store each kind of post.\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we loop through the dataset and check if the posts that start with `Ask HN`, `Show HN`, or any other combination. Once we checked this, we store each row in the corresponding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through the dataset to separate each kind of entry.\n",
    "for post in hn:\n",
    "    title = post[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(post)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(post)\n",
    "    else:\n",
    "        other_posts.append(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the length of each list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN posts: 1744\n",
      "Show HN posts: 1162\n",
      "Other posts: 17194\n"
     ]
    }
   ],
   "source": [
    "# Printing the length of each resulting dataset.\n",
    "print('Ask HN posts:', len(ask_posts))\n",
    "print('Show HN posts:', len(show_posts))\n",
    "print('Other posts:', len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have separated the ask posts and the show posts, we can check which one received more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of comments in Ask HN posts: 14\n",
      "Average number of comments in Show HN posts: 10\n"
     ]
    }
   ],
   "source": [
    "# Average number of comments in Ask HN posts.\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_ask_comments = total_ask_comments + num_comments\n",
    "\n",
    "avg_ask_comments = total_ask_comments /len(ask_posts)\n",
    "print('Average number of comments in Ask HN posts:', round(avg_ask_comments))\n",
    "\n",
    "## Average number of comments in Show HN posts.\n",
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    num_comments = int(post[4])\n",
    "    total_show_comments = total_show_comments + num_comments\n",
    "\n",
    "avg_show_comments = total_show_comments /len(show_posts)\n",
    "print('Average number of comments in Show HN posts:', round(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, `Ask HN` posts received more comments (14) than `Show HN` posts (10). Since ask posts are more likely to receive comments, we are going to focus our remaining analysis on these posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Amount of Ask Posts and Comments by Hour Created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to determine if ask posts creating at a certain time are more likely to have comments. For this analysis, we will use the following steps:\n",
    "\n",
    "- Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "- Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "We will start by calculating the amount of ask posts created per hour, along with the total amount of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datetime module.\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "# Looping through ask_posts to separate the time of the post and the number of comments.\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    num_comments = int(post[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "\n",
    "# Dictionaries to store the number of ask posts by hour and the number of comments by hour.\n",
    "counts_by_hour = {} # Ask posts by hour\n",
    "comments_by_hour = {} # Comments by hour\n",
    "\n",
    "# Counting the number of posts by hour and the number of comments by hour.\n",
    "date_format = '%m/%d/%Y %H:%M'\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comments = row[1]\n",
    "    date = dt.datetime.strptime(date, date_format)\n",
    "    hour = date.strftime('%H')\n",
    "    \n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] +=1\n",
    "        comments_by_hour[hour] += comments\n",
    "    else:\n",
    "        counts_by_hour[hour] =1\n",
    "        comments_by_hour[hour] = comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Aks HN Posts by Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the two dictionaries created above to calculate the average number of comments for post created during each hour of the day. For this purpose, we are going to store the results in a list, with the hours of the day and the average number of comments per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['00', 8.127272727272727],\n",
       " ['01', 11.383333333333333],\n",
       " ['02', 23.810344827586206],\n",
       " ['03', 7.796296296296297],\n",
       " ['04', 7.170212765957447],\n",
       " ['05', 10.08695652173913],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['08', 10.25],\n",
       " ['09', 5.5777777777777775],\n",
       " ['10', 13.440677966101696],\n",
       " ['11', 11.051724137931034],\n",
       " ['12', 9.41095890410959],\n",
       " ['13', 14.741176470588234],\n",
       " ['14', 13.233644859813085],\n",
       " ['15', 38.5948275862069],\n",
       " ['16', 16.796296296296298],\n",
       " ['17', 11.46],\n",
       " ['18', 13.20183486238532],\n",
       " ['19', 10.8],\n",
       " ['20', 21.525],\n",
       " ['21', 16.009174311926607],\n",
       " ['22', 6.746478873239437],\n",
       " ['23', 7.985294117647059]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list with the average number of comments per hour of the day.\n",
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hour.append([hour, (comments_by_hour[hour] / counts_by_hour[hour])])\n",
    "\n",
    "# Displaying the list in ascending order of the hours of the day.\n",
    "sorted(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Printing Values From a List of Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we wanted to know which hours of a day has the highest number of comments per post, we need to sort the results above to display the highest average of comments per hour.\n",
    "\n",
    "First of all, we are going to create a new list with the average comments per hour and the hours of the day in inverted order from the `avg_by_hour` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    }
   ],
   "source": [
    "# Inverting the places of hours and average number of comments per hour for sorting purposes.\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    avg_comments = row[1]\n",
    "    hour = row[0]\n",
    "    swap_avg_by_hour.append([avg_comments, hour])\n",
    "\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we sort the new list to place the hours with the highest number of average comments on top. We can print the first five hours with the higher number of average comments in a more readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for ask Posts Comments\n",
      "15:00: 38.59 average comments per post.\n",
      "02:00: 23.81 average comments per post.\n",
      "20:00: 21.52 average comments per post.\n",
      "16:00: 16.80 average comments per post.\n",
      "21:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "# Sort and print the five hours with the highest average number of comments.\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print('Top 5 hours for ask Posts Comments')\n",
    "\n",
    "for avg, hour in sorted_swap[:5]:\n",
    "    print('{}: {:.2f} average comments per post.'.format(dt.datetime.strptime(hour, '%H').strftime('%H:%M'), avg) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acording to the results, the hour when the `Ask HN` posts has the most comments is 15:00 EST in the US. The average number of comments received by the posts made at that time is highly superior than the next hour with more average comments per post (around 60% more average comments per post).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this project, we made an analysis of Hacker News post to identify which posts of those that start with `Ask HN` or `Show HN` had more number of comments per post. Besides, we wanted to know at what hour of the day we should publish a post to receive more number of comments.\n",
    "\n",
    "Acording to the results, the posts that start with `Ask HN` are those that receive in average more comments per post. Also, posts made at 15:00 hour (3:pm) EST in the US are the ones that receive more numbers of comments per post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
